# Environmental Considerations

Deploying a load balancer between client applications and NATS cluster servers (or even between servers in a cluster or between clusters in a super-cluster) is possible, but often unnecessary due to NATS' own mechanisms for balancing connections and automatically re-establishing dropped connections. Load balancers can introduce overhead and additional costs, especially if TLS termination is involved.

## Load Balancers

### Load Balancer Considerations

If you decide to use load balancers with NATS, it is crucial to understand the client and cluster connection behavior:

- **No-Discovery Behavior**: Client connections and routes are permanent. A load balancer will not distribute messages from one client connection to another or between servers. In auto-config environments, this can lead to redundant but disconnected servers.
- **Advertising**: Load balancers can interfere with server advertising mechanisms. Servers should be configured to point to the load balancer address through the advertise configuration option.
- **Packet Inspection and Idle Detection**: Improperly configured load balancers can cause issues with packet inspection and idle detection, leading to ephemeral port problems at high scale.
- **Quorum and Synchronization**: Routes or gateway connections through load balancers can disrupt JetStream quorum periods and cause undue re-synchronization and protocol overhead traffic.

### Sensible Use Cases

There are scenarios where running client connections through load balancers makes sense, such as:

- **Simplified Client Configuration**: Load balancers can simplify client configuration by presenting a single port of entry or automatically connecting to the geographically closest cluster node.
- **Cluster Transparency**: If NATS servers are set up as clusters (or superclusters), which provide transparent message routing, a load balancer can help distribute connections more efficiently.

## Networking

NATS is designed to be 'cloud native' and can be deployed in virtual environments and/or containers. However, to ensure the highest possible level of performance, consider the following:

### Instance and Storage Selection

- **Network Optimized Instances**: Non-network optimized instances may have variable network bandwidth, leading to performance degradation over time. Opt for network-optimized instance types to ensure consistent network performance.
- **Storage Options**: Local SSDs provide the best latency, while network-attached block storage (e.g., AWS EBS) can offer high throughput. Be mindful of storage type limitations and select IO-optimized storage for consistent performance.

### Virtualization and Containerization

- **Resource Limits**: Set resource limits for nats-server containers carefully. The nats-server process uses resources proportionate to the load traffic generated by client applications. High or bursty usage requires appropriate resource limits to prevent container orchestration systems from killing the server's container.
- **Memory Management**: The nats-server will use all available host memory by default. Specify GOMEMLIMIT to limit memory usage within the container. This option is available in official NATS Helm charts.

## Summary

Deploying NATS in a cloud-native environment involves careful consideration of load balancers, networking, and resource management. While load balancers can simplify client configuration and enhance connectivity, they may introduce overhead and potential issues. Proper instance and storage selection, along with careful container resource management, are crucial for maintaining optimal performance and reliability in a virtualized or containerized environment.